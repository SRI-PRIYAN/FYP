{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_api_client import PrometheusConnect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, LSTM, RepeatVector, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(\"notebook\", rc={\n",
    "    \"font.size\": 8,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"axes.labelspacing\": 10\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PrometheusConnect(url=\"http://localhost:9090\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = pd.Timestamp('2023-04-29T00:00:00IST')\n",
    "train_end_time = pd.Timestamp('2023-05-02T00:00:00IST')\n",
    "\n",
    "validate_start_time = pd.Timestamp('2023-05-03T00:01:00IST')\n",
    "validate_end_time = pd.Timestamp('2023-05-03T23:59:00IST')\n",
    "\n",
    "test_start_time = pd.Timestamp('2023-05-08T12:20:00IST')\n",
    "test_end_time = pd.Timestamp('2023-05-08T13:30:00IST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_time = pd.Timestamp('2023-05-13T00:00:00IST')\n",
    "train_end_time = pd.Timestamp('2023-05-19T00:00:00IST')\n",
    "\n",
    "validate_start_time = pd.Timestamp('2023-05-19T00:01:00IST')\n",
    "validate_end_time = pd.Timestamp('2023-05-20T00:00:00IST')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_metric(query, start_time, end_time):\n",
    "    return pc.custom_query_range(query, start_time, end_time, '1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a 2D array of size (num_values, num_nodes)\n",
    "# num_values depends on the start and end time given when fetching the metric\n",
    "def extract_values(raw_metric):\n",
    "    metric = []\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    for data in raw_metric:\n",
    "        d = np.array(data['values']).T[1]\n",
    "        scaled_d = scaler.fit_transform(d.reshape((-1, 1))).flatten()\n",
    "        metric.append(scaled_d)\n",
    "    \n",
    "    return np.array(metric, dtype=np.float64).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(query, start_time, end_time):\n",
    "    raw_metric = query_metric(query, start_time, end_time)\n",
    "    return extract_values(raw_metric)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize the Metric Values as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(metrics):\n",
    "    return metrics.transpose((1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_features(features, lookback):\n",
    "    rows = features.shape[0]\n",
    "    features = features.reshape(rows, -1)\n",
    "    res = []\n",
    "    for i in range(rows - lookback + 1):\n",
    "        res.append(features[i : i + lookback, :])\n",
    "    \n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'sum(rate(node_cpu_seconds_total{mode=\"user\"}[10m])) by (node)',\n",
    "    'node_memory_MemAvailable_bytes',\n",
    "    'sum(rate(kubelet_http_requests_total[10m])) by (kubernetes_io_hostname)',\n",
    "    '(sum(rate(node_network_transmit_bytes_total[10m])) by (node))',\n",
    "    '(sum(rate(node_network_receive_bytes_total[10m])) by (node))',\n",
    "    'sum(kubelet_running_containers{container_state=\"running\"}) by (kubernetes_io_hostname)',\n",
    "    'sum(container_processes) by (kubernetes_io_hostname)',\n",
    "    'node_sockstat_sockets_used',\n",
    "    'sum(container_sockets) by (kubernetes_io_hostname)',\n",
    "    'avg(kubelet_http_requests_duration_seconds_sum) by (kubernetes_io_hostname)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = np.array(\n",
    "    [get_metric(query, train_start_time, train_end_time) for query in queries]\n",
    ")\n",
    "\n",
    "x_train = get_features(train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = get_lstm_features(x_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_metrics = np.array(\n",
    "    [get_metric(query, validate_start_time, validate_end_time) for query in queries]\n",
    ")\n",
    "\n",
    "x_validate = get_features(validate_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validate = get_lstm_features(x_validate, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 10)\n",
    "\n",
    "encoder_input = Input(shape=input_shape)\n",
    "x = Flatten()(encoder_input)\n",
    "\n",
    "x = Dense(32, activation='LeakyReLU')(x)\n",
    "x = Dense(28, activation='LeakyReLU')(x)\n",
    "x = Dense(32, activation='LeakyReLU')(x)\n",
    "\n",
    "x = Dense(40, activation='linear')(x)\n",
    "decoder_output = Reshape(input_shape)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.Model(encoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=200,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_validate, x_validate))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 3\n",
    "num_features = 40 # 10 features for each of the 4 nodes\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(LSTM(32, activation='relu', input_shape=(timesteps, num_features), return_sequences=True))\n",
    "\n",
    "autoencoder.add(LSTM(28, activation='relu', return_sequences=True))\n",
    "autoencoder.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "\n",
    "autoencoder.add(TimeDistributed(Dense(num_features)))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics='accuracy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                shuffle=False,\n",
    "                validation_data=(x_validate, x_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(history.history['accuracy']))\n",
    "plt.plot(np.array(history.history['val_accuracy']))\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeNumberToName = {\n",
    "    0: 'gke-cluster-1-default-pool-31bf2469-0r0m',\n",
    "    1: 'gke-cluster-1-default-pool-31bf2469-818b',\n",
    "    2: 'gke-cluster-1-default-pool-31bf2469-dmtp',\n",
    "    3: 'gke-cluster-1-default-pool-31bf2469-hpfb',\n",
    "}\n",
    "\n",
    "def getNodeName(nodeNumber):\n",
    "    return nodeNumberToName[nodeNumber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attacked_nodes(x, threshold):\n",
    "    predictions = autoencoder.predict(x)\n",
    "    # For LSTM\n",
    "    # intermediate = np.mean((predictions - x) ** 2, axis=(0, 1))\n",
    "    # error = np.mean(intermediate.reshape((4, 10)), axis=1)\n",
    "    error = np.mean((predictions - x) ** 2, axis=(2, 0))\n",
    "    print(f'error => {error}')\n",
    "    nodeNumbers = np.where(error > threshold)[0]\n",
    "    return [getNodeName(nodeNumber) for nodeNumber in nodeNumbers]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Node Attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_time = pd.Timestamp('2023-05-14T12:20:00IST')\n",
    "test_end_time = pd.Timestamp('2023-05-14T13:30:00IST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = np.array(\n",
    "    [get_metric(query, test_start_time, test_end_time) for query in queries]\n",
    ")\n",
    "\n",
    "x_test = get_features(test_metrics)\n",
    "# x_test = get_lstm_features(x_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_attacked_nodes(x_test, 0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Node Attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_time = pd.Timestamp('2023-05-09T20:55:00IST')\n",
    "test_end_time = pd.Timestamp('2023-05-09T21:25:00IST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = np.array(\n",
    "    [get_metric(query, test_start_time, test_end_time) for query in queries]\n",
    ")\n",
    " \n",
    "x_test = get_features(test_metrics)\n",
    "# x_test = get_lstm_features(x_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_attacked_nodes(x_test, 0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Nodes Attacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_time = pd.Timestamp('2023-05-09T22:50:00IST')\n",
    "test_end_time = pd.Timestamp('2023-05-09T23:30:00IST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = np.array(\n",
    "    [get_metric(query, test_start_time, test_end_time) for query in queries]\n",
    ")\n",
    "\n",
    "x_test = get_features(test_metrics)\n",
    "# x_test = get_lstm_features(x_test, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_attacked_nodes(x_test, 0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
